Style Transfer Project

Image Style Transfer Using Optimization-Based Techniques

ğŸ“Œ Project Overview

This project implements an image style transfer system that synthesizes a new image by combining the structural content of a given content image with the artistic style of a separate style image. The goal is to preserve the semantic structure of the content image while transferring textures, colors, and visual patterns from the style image.

The project follows a classical optimization-based approach to style transfer, inspired by texture synthesis and multi-scale image processing techniques. It allows controlled stylization through iterative refinement while maintaining important content regions.

ğŸ§  Algorithm Structure

Load the content image and the style image and normalize their resolutions.

Apply optional color transfer to align the content image palette with the style image.

Construct multi-scale Gaussian pyramids for both images.

Extract overlapping patches of multiple sizes from the current synthesized image and the style image.

Perform nearest-neighbor patch matching between synthesized image patches and style image patches.

Aggregate matched style patches to reconstruct the image using weighted averaging.

Enforce content preservation by blending the reconstructed image with the content image.

Apply regularization and denoising to remove artifacts.

Repeat the process across scales and patch sizes until convergence.

Output the final stylized image.

ğŸ“‚ Repository Structure
.
â”œâ”€â”€ project-version2.ipynb
â”œâ”€â”€ content_images/
â”œâ”€â”€ style_images/
â”œâ”€â”€ results/
â””â”€â”€ README.md

ğŸ“¦ Requirements
pip install numpy scipy opencv-python matplotlib scikit-image tqdm

â–¶ï¸ How to Run

Clone the repository and navigate to the project directory.

Install the required Python packages.

Open the Jupyter Notebook project-version2.ipynb.

Set the paths to the content and style images.

Run all notebook cells sequentially.

ğŸ“Š Expected Outputs

The project produces stylized images that preserve the spatial structure of the content image while adopting textures and color distributions from the style image. Output images are saved in the results directory. Intermediate visualizations may be displayed in the notebook to analyze the effect of different parameters.

ğŸ“ Notes

This project is unsupervised and does not require training data. Due to randomized initialization and approximate nearest-neighbor matching, results may vary slightly between runs. The implementation is intended for academic experimentation in computer vision and image processing.
