{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b832d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Paper-Accurate Style Transfer Implementation\n",
    "Uses exact parameters from the paper:\n",
    "- r = 0.8 for robust fusion\n",
    "- gaps = [28, 18, 8, 5] for subsampling\n",
    "- IRLS for patch aggregation\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from typing import Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177e0260",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperAccurateStyleTransfer:\n",
    "    \"\"\"\n",
    "    Implements style transfer with exact paper parameters.\n",
    "    \n",
    "    Key parameters from paper:\n",
    "    - patch_sizes = [33, 21, 13, 9]\n",
    "    - gaps = [28, 18, 8, 5] (subsampling stride)\n",
    "    - r = 0.8 (robust norm for IRLS)\n",
    "    - IRLS iterations = 10\n",
    "    - EM iterations per patch = 3\n",
    "    - Pyramid levels = 3\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 patch_sizes=(33, 21, 13, 9),\n",
    "                 gaps=(28, 18, 8, 5),\n",
    "                 r_robust=0.8,\n",
    "                 irls_iterations=10,\n",
    "                 em_iterations_per_patch=3,\n",
    "                 num_levels=3):\n",
    "        \"\"\"\n",
    "        Initialize with exact paper parameters.\n",
    "        \n",
    "        Args:\n",
    "            patch_sizes: Patch sizes from large to small\n",
    "            gaps: Subsampling gaps (stride) for each patch size\n",
    "            r_robust: Robust norm parameter (0.8 in paper)\n",
    "            irls_iterations: IRLS inner iterations (10 in paper)\n",
    "            em_iterations_per_patch: EM iterations per patch size (3 in paper)\n",
    "            num_levels: Pyramid levels (3 in paper)\n",
    "        \"\"\"\n",
    "        self.patch_sizes = patch_sizes\n",
    "        self.gaps = gaps\n",
    "        self.r = r_robust\n",
    "        self.irls_iterations = irls_iterations\n",
    "        self.em_iterations = em_iterations_per_patch\n",
    "        self.num_levels = num_levels\n",
    "        \n",
    "        assert len(patch_sizes) == len(gaps), \"Must have one gap per patch size\"\n",
    "    \n",
    "    def load_image(self, path):\n",
    "        \"\"\"Load and normalize image\"\"\"\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not load: {path}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return img.astype(np.float32) / 255.0\n",
    "    \n",
    "    def save_image(self, path, img):\n",
    "        \"\"\"Save image\"\"\"\n",
    "        img = np.clip(img * 255, 0, 255).astype(np.uint8)\n",
    "        img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(path, img_bgr)\n",
    "    \n",
    "    def build_pyramid(self, image, num_levels):\n",
    "        \"\"\"Build Gaussian pyramid\"\"\"\n",
    "        pyramid = [image]\n",
    "        for _ in range(num_levels - 1):\n",
    "            image = cv2.pyrDown(image)\n",
    "            pyramid.append(image)\n",
    "        return pyramid[::-1]  # Coarse to fine\n",
    "    \n",
    "    def color_transfer(self, content, style):\n",
    "        \"\"\"Histogram matching color transfer\"\"\"\n",
    "        matched = np.zeros_like(content)\n",
    "        \n",
    "        for c in range(3):\n",
    "            src_channel = content[:, :, c].flatten()\n",
    "            tmp_channel = style[:, :, c].flatten()\n",
    "            \n",
    "            src_values, src_counts = np.unique(src_channel, return_counts=True)\n",
    "            tmp_values, tmp_counts = np.unique(tmp_channel, return_counts=True)\n",
    "            \n",
    "            src_quantiles = np.cumsum(src_counts).astype(np.float64)\n",
    "            src_quantiles /= src_quantiles[-1]\n",
    "            \n",
    "            tmp_quantiles = np.cumsum(tmp_counts).astype(np.float64)\n",
    "            tmp_quantiles /= tmp_quantiles[-1]\n",
    "            \n",
    "            interp_tmp_values = np.interp(src_quantiles, tmp_quantiles, tmp_values)\n",
    "            matched_channel = np.interp(src_channel, src_values, interp_tmp_values)\n",
    "            matched[:, :, c] = matched_channel.reshape(content.shape[:2])\n",
    "        \n",
    "        return matched\n",
    "    \n",
    "    def extract_patches_with_gap(self, image, patch_size, gap):\n",
    "        \"\"\"\n",
    "        Extract patches with specified gap (subsampling).\n",
    "        \n",
    "        Args:\n",
    "            image: Input image\n",
    "            patch_size: Size of square patches\n",
    "            gap: Stride between patches (subsampling)\n",
    "            \n",
    "        Returns:\n",
    "            patches: Flattened patches\n",
    "            positions: (i, j) positions of top-left corners\n",
    "        \"\"\"\n",
    "        h, w = image.shape[:2]\n",
    "        patches = []\n",
    "        positions = []\n",
    "        \n",
    "        # Extract on grid with spacing = gap\n",
    "        for i in range(0, h - patch_size + 1, gap):\n",
    "            for j in range(0, w - patch_size + 1, gap):\n",
    "                patch = image[i:i+patch_size, j:j+patch_size]\n",
    "                patches.append(patch.flatten())\n",
    "                positions.append((i, j))\n",
    "        \n",
    "        return np.array(patches), positions\n",
    "    \n",
    "    def find_nearest_neighbors(self, content_patches, style_patches):\n",
    "        \"\"\"Find nearest neighbor in style for each content patch\"\"\"\n",
    "        nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(style_patches)\n",
    "        distances, indices = nbrs.kneighbors(content_patches)\n",
    "        return indices.flatten()\n",
    "    \n",
    "    def robust_aggregate_IRLS(self, matched_patches, positions, output_shape, \n",
    "                             patch_size, content=None, W=None):\n",
    "        \"\"\"\n",
    "        IRLS patch aggregation with robust norm r=0.8.\n",
    "        \n",
    "        This implements Equations (8-11) from the paper.\n",
    "        \n",
    "        Args:\n",
    "            matched_patches: Matched style patches (flattened)\n",
    "            positions: Patch positions\n",
    "            output_shape: (h, w, c)\n",
    "            patch_size: Size of patches\n",
    "            content: Content image for blending\n",
    "            W: Segmentation weight map\n",
    "        \"\"\"\n",
    "        h, w, c = output_shape\n",
    "        \n",
    "        # Initialize X\n",
    "        if content is not None:\n",
    "            X = content.copy()\n",
    "        else:\n",
    "            X = np.random.rand(h, w, c).astype(np.float32) * 0.1\n",
    "        \n",
    "        # IRLS iterations (Equation 9-11)\n",
    "        for irls_iter in range(self.irls_iterations):\n",
    "            # Compute weights w_ij = ||R_ij X - z_ij||^(r-2)\n",
    "            weights = []\n",
    "            \n",
    "            for patch_flat, (i, j) in zip(matched_patches, positions):\n",
    "                patch = patch_flat.reshape(patch_size, patch_size, c)\n",
    "                \n",
    "                h_end = min(i + patch_size, h)\n",
    "                w_end = min(j + patch_size, w)\n",
    "                patch_h = h_end - i\n",
    "                patch_w = w_end - j\n",
    "                \n",
    "                # Current region in X\n",
    "                current_region = X[i:h_end, j:w_end]\n",
    "                \n",
    "                # Compute error\n",
    "                error = np.linalg.norm(current_region - patch[:patch_h, :patch_w])\n",
    "                \n",
    "                # Weight: w_ij = error^(r-2)\n",
    "                # For r=0.8: w_ij = error^(-1.2)\n",
    "                weight = np.power(error + 1e-8, self.r - 2)\n",
    "                weights.append(weight)\n",
    "            \n",
    "            weights = np.array(weights)\n",
    "            \n",
    "            # Weighted aggregation (Equation 11)\n",
    "            numerator = np.zeros((h, w, c), dtype=np.float32)\n",
    "            denominator = np.zeros((h, w, 1), dtype=np.float32)\n",
    "            \n",
    "            for weight, patch_flat, (i, j) in zip(weights, matched_patches, positions):\n",
    "                patch = patch_flat.reshape(patch_size, patch_size, c)\n",
    "                \n",
    "                h_end = min(i + patch_size, h)\n",
    "                w_end = min(j + patch_size, w)\n",
    "                patch_h = h_end - i\n",
    "                patch_w = w_end - j\n",
    "                \n",
    "                numerator[i:h_end, j:w_end] += weight * patch[:patch_h, :patch_w]\n",
    "                denominator[i:h_end, j:w_end] += weight\n",
    "            \n",
    "            denominator = np.maximum(denominator, 1e-8)\n",
    "            X_tilde = numerator / denominator\n",
    "            \n",
    "            # Content fusion (Equation 15)\n",
    "            if content is not None and W is not None:\n",
    "                # Ensure W has right shape\n",
    "                if W.ndim == 2:\n",
    "                    W = W[:, :, np.newaxis]\n",
    "                if W.shape[:2] != (h, w):\n",
    "                    W = cv2.resize(W, (w, h))\n",
    "                    W = W[:, :, np.newaxis] if W.ndim == 2 else W\n",
    "                \n",
    "                # X = (W + I)^(-1) (X_tilde + W*C)\n",
    "                # Simplified: X = (X_tilde + W*content) / (1 + W)\n",
    "                X = (X_tilde + W * content) / (1 + W)\n",
    "            else:\n",
    "                X = X_tilde\n",
    "            \n",
    "            X = np.clip(X, 0, 1)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def create_edge_segmentation(self, content):\n",
    "        \"\"\"Create simple edge-based segmentation mask\"\"\"\n",
    "        gray = cv2.cvtColor((content * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        kernel = np.ones((11, 11), np.uint8)\n",
    "        mask = cv2.dilate(edges, kernel, iterations=1)\n",
    "        mask = mask.astype(np.float32) / 255.0\n",
    "        mask = gaussian_filter(mask, sigma=2.0)\n",
    "        return mask\n",
    "    \n",
    "    def process_with_patch_size(self, content_level, style_level, patch_size, gap,\n",
    "                               prev_result=None, W=None):\n",
    "        \"\"\"\n",
    "        Process one pyramid level with one patch size.\n",
    "        \n",
    "        Args:\n",
    "            content_level: Content at this pyramid level\n",
    "            style_level: Style at this pyramid level  \n",
    "            patch_size: Size of patches to use\n",
    "            gap: Subsampling gap for this patch size\n",
    "            prev_result: Previous result to build on\n",
    "            W: Segmentation weight map\n",
    "        \"\"\"\n",
    "        h, w = content_level.shape[:2]\n",
    "        \n",
    "        print(f\"      Patch {patch_size}×{patch_size}, gap={gap}, overlap={(patch_size-gap)/patch_size*100:.0f}%\")\n",
    "        \n",
    "        # Initialize\n",
    "        if prev_result is None:\n",
    "            # Paper initialization: content + strong noise (σ=50)\n",
    "            X = content_level + np.random.randn(*content_level.shape) * (50.0/255.0)\n",
    "            X = np.clip(X, 0, 1).astype(np.float32)\n",
    "        else:\n",
    "            # Upsample previous result\n",
    "            if prev_result.shape[:2] != (h, w):\n",
    "                X = cv2.resize(prev_result, (w, h))\n",
    "            else:\n",
    "                X = prev_result.copy()\n",
    "        \n",
    "        # Extract all style patches once\n",
    "        style_patches, _ = self.extract_patches_with_gap(style_level, patch_size, gap)\n",
    "        print(f\"        Extracted {len(style_patches)} style patches\")\n",
    "        \n",
    "        # EM iterations (3 per patch size in paper)\n",
    "        for em_iter in range(self.em_iterations):\n",
    "            print(f\"        EM iteration {em_iter + 1}/{self.em_iterations}...\")\n",
    "            \n",
    "            # E-step: Extract patches from current result and find matches\n",
    "            X_patches, positions = self.extract_patches_with_gap(X, patch_size, gap)\n",
    "            \n",
    "            # Find nearest neighbors\n",
    "            nn_indices = self.find_nearest_neighbors(X_patches, style_patches)\n",
    "            matched_patches = style_patches[nn_indices]\n",
    "            \n",
    "            # M-step: IRLS aggregation with r=0.8\n",
    "            X = self.robust_aggregate_IRLS(\n",
    "                matched_patches, positions, (h, w, 3),\n",
    "                patch_size, content_level, W\n",
    "            )\n",
    "            \n",
    "            # Color transfer (after each EM iteration)\n",
    "            X = self.color_transfer(X, style_level)\n",
    "            \n",
    "            # Denoise (Domain Transform in paper, we use Gaussian)\n",
    "            X = gaussian_filter(X, sigma=0.5)\n",
    "            X = np.clip(X, 0, 1)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def transfer(self, content_path, style_path, output_path,\n",
    "                use_segmentation=True, max_size=400):\n",
    "        \"\"\"\n",
    "        Main style transfer with exact paper parameters.\n",
    "        \"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"PAPER-ACCURATE STYLE TRANSFER\")\n",
    "        print(f\"Parameters: r={self.r}, gaps={self.gaps}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Load images\n",
    "        print(\"\\n1. Loading images...\")\n",
    "        content = self.load_image(content_path)\n",
    "        style = self.load_image(style_path)\n",
    "        \n",
    "        # Resize to max_size (paper uses 400×400)\n",
    "        # h, w = content.shape[:2]\n",
    "        # if max(h, w) > max_size:\n",
    "        #     scale = max_size / max(h, w)\n",
    "        #     new_h, new_w = int(h * scale), int(w * scale)\n",
    "        #     content = cv2.resize(content, (new_w, new_h))\n",
    "        #     print(f\"   Content resized to: {content.shape}\")\n",
    "        \n",
    "        # h, w = style.shape[:2]\n",
    "        # if max(h, w) > max_size:\n",
    "        #     scale = max_size / max(h, w)\n",
    "        #     new_h, new_w = int(h * scale), int(w * scale)\n",
    "        #     style = cv2.resize(style, (new_w, new_h))\n",
    "        #     print(f\"   Style resized to: {style.shape}\")\n",
    "        content = cv2.resize(content, (max_size, max_size), interpolation=cv2.INTER_AREA)\n",
    "        style = cv2.resize(style, (max_size, max_size), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Create segmentation mask\n",
    "        W = None\n",
    "        if use_segmentation:\n",
    "            print(\"\\n2. Creating segmentation mask...\")\n",
    "            W = self.create_edge_segmentation(content)\n",
    "        \n",
    "        # Initial color transfer\n",
    "        print(\"\\n3. Initial color transfer...\")\n",
    "        content_colored = self.color_transfer(content, style)\n",
    "        \n",
    "        # Build pyramids\n",
    "        print(f\"\\n4. Building pyramids ({self.num_levels} levels)...\")\n",
    "        content_pyramid = self.build_pyramid(content_colored, self.num_levels)\n",
    "        style_pyramid = self.build_pyramid(style, self.num_levels)\n",
    "        \n",
    "        for i, (c, s) in enumerate(zip(content_pyramid, style_pyramid)):\n",
    "            print(f\"   Level {i}: content {c.shape}, style {s.shape}\")\n",
    "        \n",
    "        # Process pyramid levels\n",
    "        result = None\n",
    "        \n",
    "        for level in range(self.num_levels):\n",
    "            print(f\"\\n5. PYRAMID LEVEL {level + 1}/{self.num_levels}\")\n",
    "            content_level = content_pyramid[level]\n",
    "            style_level = style_pyramid[level]\n",
    "            \n",
    "            # Resize segmentation for this level\n",
    "            W_level = None\n",
    "            if W is not None:\n",
    "                h_level, w_level = content_level.shape[:2]\n",
    "                W_level = cv2.resize(W, (w_level, h_level))\n",
    "            \n",
    "            # Process each patch size with its corresponding gap\n",
    "            for patch_size, gap in zip(self.patch_sizes, self.gaps):\n",
    "                # Skip if patch too large for this level\n",
    "                min_dim = min(content_level.shape[:2])\n",
    "                if patch_size >= min_dim:\n",
    "                    print(f\"    Skipping patch {patch_size} (too large for {min_dim})\")\n",
    "                    continue\n",
    "                \n",
    "                result = self.process_with_patch_size(\n",
    "                    content_level, style_level,\n",
    "                    patch_size, gap,\n",
    "                    prev_result=result,\n",
    "                    W=W_level\n",
    "                )\n",
    "        \n",
    "        # Final color transfer\n",
    "        print(\"\\n6. Final color transfer...\")\n",
    "        result = self.color_transfer(result, style)\n",
    "        \n",
    "        # Save\n",
    "        print(f\"\\n7. Saving to {output_path}...\")\n",
    "        self.save_image(output_path, result)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"COMPLETE!\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4dab159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PAPER-ACCURATE STYLE TRANSFER\n",
      "Parameters: r=0.8, gaps=(28, 18, 8, 5)\n",
      "======================================================================\n",
      "\n",
      "1. Loading images...\n",
      "\n",
      "2. Creating segmentation mask...\n",
      "\n",
      "3. Initial color transfer...\n",
      "\n",
      "4. Building pyramids (3 levels)...\n",
      "   Level 0: content (100, 100, 3), style (100, 100, 3)\n",
      "   Level 1: content (200, 200, 3), style (200, 200, 3)\n",
      "   Level 2: content (400, 400, 3), style (400, 400, 3)\n",
      "\n",
      "5. PYRAMID LEVEL 1/3\n",
      "      Patch 33×33, gap=28, overlap=15%\n",
      "        Extracted 9 style patches\n",
      "        EM iteration 1/3...\n",
      "        EM iteration 2/3...\n",
      "        EM iteration 3/3...\n",
      "      Patch 21×21, gap=18, overlap=14%\n",
      "        Extracted 25 style patches\n",
      "        EM iteration 1/3...\n",
      "        EM iteration 2/3...\n",
      "        EM iteration 3/3...\n",
      "      Patch 13×13, gap=8, overlap=38%\n",
      "        Extracted 121 style patches\n",
      "        EM iteration 1/3...\n",
      "        EM iteration 2/3...\n",
      "        EM iteration 3/3...\n",
      "      Patch 9×9, gap=5, overlap=44%\n",
      "        Extracted 361 style patches\n",
      "        EM iteration 1/3...\n",
      "        EM iteration 2/3...\n",
      "        EM iteration 3/3...\n",
      "\n",
      "5. PYRAMID LEVEL 2/3\n",
      "      Patch 33×33, gap=28, overlap=15%\n",
      "        Extracted 36 style patches\n",
      "        EM iteration 1/3...\n",
      "        EM iteration 2/3...\n",
      "        EM iteration 3/3...\n",
      "      Patch 21×21, gap=18, overlap=14%\n",
      "        Extracted 100 style patches\n",
      "        EM iteration 1/3...\n",
      "        EM iteration 2/3...\n",
      "        EM iteration 3/3...\n",
      "      Patch 13×13, gap=8, overlap=38%\n",
      "        Extracted 576 style patches\n",
      "        EM iteration 1/3...\n",
      "        EM iteration 2/3...\n",
      "        EM iteration 3/3...\n",
      "      Patch 9×9, gap=5, overlap=44%\n",
      "        Extracted 1521 style patches\n",
      "        EM iteration 1/3...\n",
      "        EM iteration 2/3...\n",
      "        EM iteration 3/3...\n",
      "\n",
      "5. PYRAMID LEVEL 3/3\n",
      "      Patch 33×33, gap=28, overlap=15%\n",
      "        Extracted 196 style patches\n",
      "        EM iteration 1/3...\n",
      "        EM iteration 2/3...\n",
      "        EM iteration 3/3...\n",
      "      Patch 21×21, gap=18, overlap=14%\n",
      "        Extracted 484 style patches\n",
      "        EM iteration 1/3...\n",
      "        EM iteration 2/3...\n",
      "        EM iteration 3/3...\n",
      "      Patch 13×13, gap=8, overlap=38%\n",
      "        Extracted 2401 style patches\n",
      "        EM iteration 1/3...\n",
      "        EM iteration 2/3...\n",
      "        EM iteration 3/3...\n",
      "      Patch 9×9, gap=5, overlap=44%\n",
      "        Extracted 6241 style patches\n",
      "        EM iteration 1/3...\n",
      "        EM iteration 2/3...\n",
      "        EM iteration 3/3...\n",
      "\n",
      "6. Final color transfer...\n",
      "\n",
      "7. Saving to V2_results/res(33, 21, 13, 9) - (28, 18, 8, 5).jpg...\n",
      "\n",
      "======================================================================\n",
      "COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "     \n",
    "    patch_sizes=(33, 21, 13, 9)\n",
    "    gaps=(28,18,8,5)\n",
    "    \n",
    "    content_path = \"./Data/content/house3.jpg\"\n",
    "    style_path = \"./Data/style/starry_night.jpg\"\n",
    "    output_path = f\"V2_results/res{patch_sizes} - {gaps}.jpg\"\n",
    "    \n",
    "    max_size = 400\n",
    "    \n",
    "    # Create transfer object with exact paper parameters\n",
    "    st = PaperAccurateStyleTransfer(\n",
    "        patch_sizes ,\n",
    "        gaps,\n",
    "        r_robust=0.8,\n",
    "        irls_iterations=3,\n",
    "        em_iterations_per_patch=3,\n",
    "        num_levels=3\n",
    "    )\n",
    "    \n",
    "    # Run transfer\n",
    "    result = st.transfer(content_path, style_path, output_path, max_size=max_size)\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
